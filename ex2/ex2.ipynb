{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "from collections import Counter\n",
    "import string\n",
    "import itertools\n",
    "import re\n",
    "import json\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = '..' + os.sep + 'Corpus-spell-AP88'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus = [f'{corpus_path}/ap881229', f'{corpus_path}/ap881230', f'{corpus_path}/ap881231']\n",
    "corpus = os.listdir(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ap880827'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20785/1095099697.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfile_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mff\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0min_text_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ap880827'"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for doc in corpus:\n",
    "    file_text = []\n",
    "    ff =  open(f'{corpus_path}{os.sep}{doc}', 'r', encoding='utf-8')\n",
    "    in_text_block = False\n",
    "    lines = ff.readlines()\n",
    "    for line in lines:\n",
    "        if line.startswith('<TEXT>'):\n",
    "            in_text_block = True\n",
    "            \n",
    "        elif line.startswith('</TEXT>'):\n",
    "            in_text_block = False\n",
    "        elif in_text_block == True:\n",
    "            line_fixed = line.translate(str.maketrans('', '', \"\"\"!\"#$%&()*+,./:;<=>?@[\\]^_`{|}~\"\"\"))\n",
    "            line_tokens = line_fixed.split()\n",
    "            for tok in line_tokens:\n",
    "                if tok.isalpha() and tok.islower():\n",
    "                    tokens.append(tok)\n",
    "        else:\n",
    "                pass\n",
    "fw = open(f'corpus_tokens.json', 'w', encoding='utf-8')\n",
    "fw.write( json.dumps(Counter(tokens), indent=4))\n",
    "fw.close()\n",
    "fw = open(f'corpus_tokens.txt', 'w', encoding='utf-8')\n",
    "for t in set(tokens):\n",
    "    fw.write(f'{t}\\n')\n",
    "fw.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [''.join([pair[0], pair[1]]) for pair in itertools.combinations(string.ascii_lowercase,2)]\n",
    "pairs.extend([''.join([a[0], a[1]]) for a in zip(string.ascii_lowercase, string.ascii_lowercase) ])\n",
    "pairs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_string = ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_regexes = [(p, re.compile(p)) for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts = [(p[0], max(1,len(p[1].findall(long_string)))) for p in pair_regexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts_dict = dict(pair_counts)\n",
    "with open('letter_pair_counts.json', 'w') as f:\n",
    "    f.write(json.dumps(pair_counts_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now execute these in bash\n",
    "# cat corpus_tokens.txt | aspell -d en_US list > incorrect.txt\n",
    "# cat incorrect.txt | aspell -d en_US -a > suggestions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f144b688d3ae7e74bf7b8cd8d07b61a52afb51aca0ece1f40d9684ac5ed395c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('inlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
