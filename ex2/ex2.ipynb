{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "from collections import Counter\n",
    "import string\n",
    "import itertools\n",
    "import re\n",
    "import json\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = '..' + os.sep + 'Corpus-spell-AP88'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [f'{corpus_path}/ap881229', f'{corpus_path}/ap881230', f'{corpus_path}/ap881231']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for doc in corpus:\n",
    "    file_text = []\n",
    "    ff =  open(doc, 'r', encoding='utf-8')\n",
    "    in_text_block = False\n",
    "    lines = ff.readlines()\n",
    "    for line in lines:\n",
    "        if line.startswith('<TEXT>'):\n",
    "            in_text_block = True\n",
    "            \n",
    "        elif line.startswith('</TEXT>'):\n",
    "            in_text_block = False\n",
    "        elif in_text_block == True:\n",
    "            line_fixed = line.translate(str.maketrans('', '', \"\"\"!\"#$%&()*+,./:;<=>?@[\\]^_`{|}~\"\"\"))\n",
    "            line_tokens = line_fixed.split()\n",
    "            for tok in line_tokens:\n",
    "                if tok.isalpha() and tok.islower():\n",
    "                    tokens.append(tok)\n",
    "        else:\n",
    "                pass\n",
    "fw = open(f'corpus_tokens.txt', 'w', encoding='utf-8')\n",
    "for c in set(tokens):\n",
    "    fw.write(f'{c.strip()}\\n')\n",
    "fw.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [''.join([pair[0], pair[1]]) for pair in itertools.combinations(string.ascii_lowercase,2)]\n",
    "pairs.extend([''.join([a[0], a[1]]) for a in zip(string.ascii_lowercase, string.ascii_lowercase) ])\n",
    "pairs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_string = ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_regexes = [(p, re.compile(p)) for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts = [(p[0], max(1,len(p[1].findall(long_string)))) for p in pair_regexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts_dict = dict(pair_counts)\n",
    "with open('letter_pair_counts', 'w') as f:\n",
    "    f.write(json.dumps(pair_counts_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now execute these in bash\n",
    "# cat corpus_tokens.txt | aspell -d en_US list > incorrect.txt\n",
    "# cat incorrect.txt | aspell -d en_US -a > suggestions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f144b688d3ae7e74bf7b8cd8d07b61a52afb51aca0ece1f40d9684ac5ed395c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('inlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
